
env_args:
    #env: 'TicTacToe'
    # env: 'Geister'
    # env: 'HungryGeese'
    # env: 'handyrl.envs.parallel_tictactoe'  # specify by path
    env: 'simpletask'
    param:
        depth: 8 #深度(変更可能)
        hyperplane_n: 4 #超平面次元数(変更可能)
        treasure: [[7, 4, 4, 4, 4]] #報酬の場所(変更可能) #0番目は必ず(深度-1)になるように
        set_reward: 1 #報酬の値(変更可能)
        start_random: True #初期地点をランダムにするか固定にするか / True: ランダムにする, False: 固定する
        pomdp_setting: #途中報酬への対応(POMDP)
            pom_bool: False #途中報酬を導入するか否か
            pom_state: [1, 1] #途中報酬の座標(ここを通らないと報酬が得られない)

train_args:
    # depth: 3 #深度(変更可能)
    # hyperplane_n: 2 #超平面次元数(変更可能)
    # treasure: [[2, 1, 0], [2, 2, 1]] #報酬の場所(変更可能) #0番目は必ず(深度-1)になるように
    # set_reward: 1 #報酬の値(変更可能)
    # start_random: True #初期地点をランダムにするか固定にするか / True: ランダムにする, False: 固定する
    # pomdp_setting: #途中報酬への対応(POMDP)
    #     pom_bool: True #途中報酬を導入するか否か
    #     pom_state: [1, 1, 0] #途中報酬の座標(ここを通らないと報酬が得られない)

    turn_based_training: False
    # turn_based_training: True
    observation: False
    gamma: 0.9
    forward_steps: 16
    burn_in_steps: 0  # for RNNs
    compress_steps: 4
    entropy_regularization: 0.25
    # entropy_regularization: 1.0
    entropy_regularization_decay: 1.0
    # update_episodes: 100
    update_episodes: 200
    # batch_size: 128
    batch_size: 256
    # minimum_episodes: 300
    # maximum_episodes: 1000
    minimum_episodes: 100000
    maximum_episodes: 200000
    # epochs: 5
    epochs: 500
    num_batchers: 2
    eval_rate: 0.1
    worker:
        num_parallel: 1
    lambda: 0.7
    policy_target: 'TD' # 'UPGO' 'VTRACE' 'TD' 'MC'
    value_target: 'TD' # 'VTRACE' 'TD' 'MC'
    eval:
        opponent: ['random']
    seed: 0
    restart_epoch: 0


worker_args:
    server_address: '192.168.11.21'
    num_parallel: 128
