
env_args:
    # env: 'TicTacToe'
    # env: 'Geister'
    # env: 'HungryGeese'
    # env: 'handyrl.envs.parallel_tictactoe'  # specify by path
    env: 'simpletask'
    param:
        depth: 8 # 深度(変更可能)
        hyperplane_n: 2 # 超平面次元数(変更可能)
        treasure: [[7, 4, 4]] # 報酬の場所(変更可能) #0番目は必ず(深度-1)になるように
        set_reward: [1] # 報酬の値(変更可能)
        other_reward: 0 # treasure以外に到達した時の報酬設定
        start_random: True # 初期地点をランダムにするか固定にするか / True: ランダムにする, False: 固定する
        pomdp_setting: # 途中報酬への対応(POMDP)
            pom_bool: False # 途中報酬を導入するか否か
            pom_state: [1, 1] # 途中報酬の座標(ここを通らないと報酬が得られない)
        random_trasures_setting: # 報酬の場所をランダムに設定
            random_trasures_bool: False # 報酬の場所をランダムに設定するか / True: 設定する, False: 設定しない
            random_trasures_num: 1 # 報酬の場所の個数
        random_reward_setting: # 確率的な報酬設定 ※現在はPOMDPとの併用不可
            random_reward_bool: False # 確率的な報酬で設定するか / True: 設定する, False: 設定しない
            random_reward: [[1], [1, 100]] # 報酬の量, 各要素は報酬の位置に対応
            random_reward_p: [[1], [0.9, 0.1]] # 報酬の確率 , 各要素の合計値は1になるように設定
        uns_setting:
            uns_bool: False # 非定常の導入するか否か
            uns_num: 1000 # 非定常の周期（報酬位置をどの程度の間隔で変更するか）
        observation_noise: 2 # 観測時にノイズがあるか（ 0:なし, 1:ノイズ小, 2;ノイズ大）
        jyotai_boolkari: False # ランダムな状態量の有無

train_args:
    turn_based_training: False
    observation: False
    gamma: 0.9
    forward_steps: 1
    burn_in_steps: 0  # for RNNs
    compress_steps: 4
    entropy_regularization: 0
    entropy_regularization_decay: 1.0
    update_episodes: 200
    batch_size: 256
    minimum_episodes: 100000
    maximum_episodes: 200000
    epochs: 500
    num_batchers: 1
    eval_rate: 0.1
    worker:
        num_parallel: 5
    lambda: 0.7
    policy_target: 'TD' # 'UPGO' 'VTRACE' 'TD' 'MC'
    value_target: 'TD' # 'VTRACE' 'TD' 'MC'
    eval:
        opponent: ['random']
    seed: 0
    restart_epoch: 0


worker_args:
    server_address: '192.168.11.24'
    num_parallel: 128